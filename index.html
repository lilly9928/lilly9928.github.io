<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jieun Kim</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/hamster-face.png" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Jieun Kim
                  </p>
                  <p>
                    Hi! I'm a Ph.D. student at the <a href="https://sclab.yonsei.ac.kr/home">Soft Computing Lab</a> at
                    <a href="https://graduate.yonsei.ac.kr/">Yonsei University</a>, advised by
                    <a href="https://sclab.yonsei.ac.kr/people">Prof. Sung-Bae Cho</a>.
                  </p>
                  <p>
                    My research focuses on <strong>vision, multimodal learning, and trustworthy AI (XAI)</strong> .
                    I'm particularly interested in understanding how models perceive and reason about the visual world,
                    and how we can ensure their outputs are interpretable and reliable.
                  </p>
                  <p>
                    Currently, I am actively seeking research internship opportunities where I can contribute to and
                    collaborate on cutting-edge problems in vision and multimodal AI.
                  </p>


                  <p style="text-align:center">
                    <a href="mailto:lilly9928@yonsei.ac.kr">Email</a> &nbsp;/&nbsp;
                    <a href="">CV</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/www.linkedin.com/in/jieunnn">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/lilly9928">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/profile.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- News Title -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>News</h2> <!-- 여기에 아래쪽 마진 추가 -->
                </td>
              </tr>
            </tbody>
          </table>

          <!-- News Content -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin:auto;">
            <tbody>
              <tr>
                <td style="padding:12px;width:100%;vertical-align:middle">
                  <span class="congrats-badge"
                    style=" padding:2px 6px; border-radius:4px; font-weight:bold; margin-right:8px;">🎉</span>
                  2025.06 : One paper on Mitigating Hallucination of Visual Language Model is accepted at <strong>ICCV
                    2025</strong>!
                </td>

              </tr>
            </tbody>
          </table>




          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width: 100%; border: 0px;border-spacing: 0px;border-collapse: separate;margin-right: auto;margin-left: auto;">
            <tbody>



              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/situW.png" style="width:180px; height:100px;display:block;">
                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">Context-aware Logical Reasoning in Language Model via Situation Working
                    Memory</span>
                  </a>
                  <br>
                  <strong>Jieun Kim</strong>, YoungHae Choi, Seoha Lim, Sung-Bae Cho
                  <br>
                  <em>Under Review</em>, 2025
                  <br>
                  <!-- <a href="">page</a>
                  /
                  <a href="">paper</a> -->
                </td>
              </tr>
              <!--PAPER END-->

              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/fuzzycd_img.png" style="width:180px; height:100px;display:block;">
                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">Fuzzy Contrastive Decoding to Alleviate Object Hallucination in Large
                    Vision-Language Models</span>
                  </a>
                  <br>
                   <strong>Jieun Kim</strong>, <span class="tooltip"><a>Jinmyeong Kim</a></span> , Yoonji Kim, Sung-Bae Cho
                  <!-- <strong>Jieun Kim</strong>, <span class="tooltip"><a href="https://tobe-honest.github.io/">Jinmyeong Kim</a></span> , Yoonji Kim, Sung-Bae Cho -->
                  <br>
                  <em>ICCV</em>, 2025
                  <br>
                  <a href="">page</a>
                  /
                  <a href="">paper</a>
                </td>
              </tr>
              <!--PAPER END-->
              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/survey.png" style="width:180px; height:100px;display:block;">

                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">Visual Question Answering: A Survey of Methods, Datasets, Evaluation, and
                    Challenges</span>
                  </a>
                  <br>
                  Byeong Su Kim, <strong>Jieun Kim</strong>, Deokwoo Lee, Beakcheol Jang
                  <br>
                  <em>ACM Computing Surveys</em>, 2025 (IF 23.8)
                  <br>
                  <a href="">paper</a>
                </td>
              </tr>
              <!--PAPER END-->

              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/locot.png" style="width:180px; height:100px;  display:block;">
                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">LoCoT: Logical Chain-of-Thought Prompting for Knowledge-Based Visual
                    Reasoning</span>
                  </a>
                  <br>
                  <strong>Jieun Kim</strong>, Gatum Erlangga, Yoon Choi, Sung-Bae Cho
                  <br>
                  <em>Under Review</em>, 2024
                  <br>
                  <!-- <a href="">page</a>
                  /
                  <a href="">paper</a> -->
                </td>
              </tr>
              <!--PAPER END-->


              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/noImage.jpg" style="width:180px; height:100px;display:block;">

                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">FTT: Fourier Transform based Transformer for Brain CT Report
                    Generation</span>
                  </a>
                  <br>
                  <strong>Jieun Kim</strong>, Byeong Su Kim, Insung Choi, Zepa Yang and Beakcheol Jang
                  <br>
                  <em>ICAIIC</em>, 2024
                  <br>
                </td>
              </tr>
              <!--PAPER END-->
              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/noImage.jpg" style="width:180px; height:100px;display:block;">

                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">Facial Expression Recognition using Visual Transformer with Histogram of
                    Oriented Gradients</span>
                  </a>
                  <br>
                  <strong>Jieun Kim</strong>, Ju O Kim, Seungwan Je, Deokwoo Lee
                  <br>
                  <em>Electronic Imaging</em>, Vol. 7, oral 19 Jan 2023
                  <br>
                </td>
              </tr>
              <!--PAPER END-->
              <!--PAPER START-->
              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_stop()" bgcolor="">
                <td style="padding:20px;width:30%;">
                  <img src="images/noImage.jpg" style="width:180px; height:100px;display:block;">

                </td>
                <td style="padding:0px;width:70%;vertical-align:middle">
                  <span class="papertitle">Facial Expression Recognition Robust to Occlusion using Spatial Transformer
                    Network with Triplet Loss Function</span>
                  </a>
                  <br>
                  <strong>Jieun Kim</strong>, Eung-Joo Lee, Deokwoo Lee
                  <br>
                  <em>SPIE 12101, Pattern Recognition and Tracking </em>, 2022
                  <br>
                </td>
              </tr>
              <!--PAPER END-->


            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <p style="text-align:center;font-size:small;">
                    Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
